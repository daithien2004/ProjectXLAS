import streamlit as st
import cv2
import numpy as np
from PIL import Image
from config import (
    FRUIT_CLASSES, FRUIT_INPUT_WIDTH, FRUIT_INPUT_HEIGHT,
    FRUIT_SCORE_THRESHOLD, FRUIT_NMS_THRESHOLD, FRUIT_CONFIDENCE_THRESHOLD,
    FRUIT_FONT_FACE, FRUIT_FONT_SCALE, FRUIT_THICKNESS, FRUIT_COLORS
)

@st.cache_resource
def load_fruit_model():
    """T·∫£i m√¥ h√¨nh nh·∫≠n d·∫°ng tr√°i c√¢y."""
    try:
        net = cv2.dnn.readNet("./Source/NhanDienTraiCay/trai_cay.onnx")
        return net
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i m√¥ h√¨nh trai_cay.onnx: {str(e)}")
        return None

def draw_label(im, label, x, y):
    """V·∫Ω nh√£n l√™n ·∫£nh t·∫°i v·ªã tr√≠ (x, y)."""
    text_size = cv2.getTextSize(label, FRUIT_FONT_FACE, FRUIT_FONT_SCALE, FRUIT_THICKNESS)
    dim, baseline = text_size[0], text_size[1]
    cv2.rectangle(im, (x, y), (x + dim[0], y + dim[1] + baseline), FRUIT_COLORS['BLACK'], cv2.FILLED)
    cv2.putText(im, label, (x, y + dim[1]), FRUIT_FONT_FACE, FRUIT_FONT_SCALE, FRUIT_COLORS['YELLOW'], FRUIT_THICKNESS, cv2.LINE_AA)

def pre_process(input_image, net):
    """Ti·ªÅn x·ª≠ l√Ω ·∫£nh tr∆∞·ªõc khi ƒë∆∞a v√†o m√¥ h√¨nh."""
    try:
        blob = cv2.dnn.blobFromImage(input_image, 1/255, (FRUIT_INPUT_WIDTH, FRUIT_INPUT_HEIGHT), [0, 0, 0], 1, crop=False)
        net.setInput(blob)
        outputs = net.forward(net.getUnconnectedOutLayersNames())
        return outputs
    except Exception as e:
        st.error(f"L·ªói trong qu√° tr√¨nh ti·ªÅn x·ª≠ l√Ω: {str(e)}")
        return None

def post_process(input_image, outputs):
    """H·∫≠u x·ª≠ l√Ω k·∫øt qu·∫£ t·ª´ m√¥ h√¨nh ƒë·ªÉ v·∫Ω h·ªôp v√† nh√£n, tr·∫£ v·ªÅ ·∫£nh v√† danh s√°ch ph√°t hi·ªán."""
    if outputs is None:
        st.warning("Kh√¥ng nh·∫≠n ƒë∆∞·ª£c k·∫øt qu·∫£ t·ª´ m√¥ h√¨nh.")
        return input_image, []

    class_ids = []
    confidences = []
    boxes = []
    rows = outputs[0].shape[1]
    image_height, image_width = input_image.shape[:2]
    x_factor = image_width / FRUIT_INPUT_WIDTH
    y_factor = image_height / FRUIT_INPUT_HEIGHT

    # Thu th·∫≠p c√°c ph√°t hi·ªán
    for r in range(rows):
        row = outputs[0][0][r]
        confidence = row[4]
        if confidence >= FRUIT_CONFIDENCE_THRESHOLD:
            classes_scores = row[5:]
            class_id = np.argmax(classes_scores)
            if classes_scores[class_id] > FRUIT_SCORE_THRESHOLD and class_id < len(FRUIT_CLASSES):
                confidences.append(float(confidence))
                class_ids.append(class_id)
                cx, cy, w, h = row[0], row[1], row[2], row[3]
                left = int((cx - w/2) * x_factor)
                top = int((cy - h/2) * y_factor)
                width = int(w * x_factor)
                height = int(h * y_factor)
                box = np.array([left, top, width, height])
                boxes.append(box)

    if not boxes:
        st.warning("Kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c tr√°i c√¢y n√†o trong ·∫£nh.")
        return input_image, []

    # √Åp d·ª•ng Non-Maximum Suppression
    try:
        indices = cv2.dnn.NMSBoxes(boxes, confidences, FRUIT_CONFIDENCE_THRESHOLD, FRUIT_NMS_THRESHOLD)
        if isinstance(indices, tuple):
            indices = indices[0]  # OpenCV c≈© tr·∫£ v·ªÅ tuple
        indices = indices.flatten() if indices.ndim > 1 else indices

        if len(indices) == 0:
            st.warning("Kh√¥ng c√≥ ƒë·ªëi t∆∞·ª£ng n√†o v∆∞·ª£t qua NMS.")
            return input_image, []

        # Danh s√°ch c√°c ph√°t hi·ªán
        detections = []
        for i in indices:
            if i < len(class_ids) and i < len(confidences):
                box = boxes[i]
                left = box[0]
                top = box[1]
                width = box[2]
                height = box[3]
                cv2.rectangle(input_image, (left, top), (left + width, top + height), FRUIT_COLORS['BLUE'], 3 * FRUIT_THICKNESS)
                label = "{}:{:.2f}".format(FRUIT_CLASSES[class_ids[i]], confidences[i])
                draw_label(input_image, label, left, top)
                detections.append({
                    "class": FRUIT_CLASSES[class_ids[i]],
                    "confidence": confidences[i],
                    "box": box
                })
            else:
                st.warning(f"Ch·ªâ s·ªë {i} kh√¥ng h·ª£p l·ªá trong indices.")

        return input_image, detections
    except Exception as e:
        st.error(f"L·ªói trong qu√° tr√¨nh h·∫≠u x·ª≠ l√Ω: {str(e)}")
        return input_image, []

def process_fruit_recognition(net):
    """X·ª≠ l√Ω nh·∫≠n d·∫°ng tr√°i c√¢y t·ª´ ·∫£nh t·∫£i l√™n."""
    if net is None:
        st.error("Kh√¥ng th·ªÉ t·∫£i m√¥ h√¨nh nh·∫≠n d·∫°ng tr√°i c√¢y. Vui l√≤ng ki·ªÉm tra file trai_cay.onnx.")
        return

    st.header("üçé Nh·∫≠n d·∫°ng tr√°i c√¢y")
    st.write("**M√¥ t·∫£**: Nh·∫≠n d·∫°ng 5 lo·∫°i tr√°i c√¢y (B∆∞·ªüi, D∆∞a H·∫•u, S·∫ßu Ri√™ng, T√°o, Thanh Long) t·ª´ ·∫£nh t·∫£i l√™n.")

    img_file_buffer = st.file_uploader("üì§ T·∫£i l√™n ·∫£nh ch·ª©a tr√°i c√¢y", type=["bmp", "png", "jpg", "jpeg"])

    if img_file_buffer is not None:
        # Hi·ªÉn th·ªã ·∫£nh g·ªëc
        try:
            image = Image.open(img_file_buffer)
            frame = np.array(image)
            if frame.ndim == 2:  # ·∫¢nh x√°m
                frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)
            else:
                frame = frame[:, :, [2, 1, 0]]  # BGR -> RGB
            st.image(image, caption="·∫¢nh g·ªëc", use_column_width=True)
        except Exception as e:
            st.error(f"L·ªói khi ƒë·ªçc ·∫£nh: {str(e)}")
            return

        if st.button("üîç Nh·∫≠n d·∫°ng"):
            # X·ª≠ l√Ω ·∫£nh
            detections = pre_process(frame, net)
            if detections is not None:
                img, detected_fruits = post_process(frame.copy(), detections)

                # Th√™m th√¥ng tin hi·ªáu su·∫•t
                t, _ = net.getPerfProfile()
                label = 'Inference time: %.2f ms' % (t * 1000.0 / cv2.getTickFrequency())
                cv2.putText(img, label, (20, 40), FRUIT_FONT_FACE, FRUIT_FONT_SCALE, FRUIT_COLORS['RED'], FRUIT_THICKNESS, cv2.LINE_AA)

                # Hi·ªÉn th·ªã k·∫øt qu·∫£
                st.image(img, caption="K·∫øt qu·∫£ nh·∫≠n d·∫°ng", use_column_width=True, channels="BGR")

                # Hi·ªÉn th·ªã danh s√°ch tr√°i c√¢y ƒë∆∞·ª£c ph√°t hi·ªán
                if detected_fruits:
                    st.subheader("Tr√°i c√¢y ƒë∆∞·ª£c ph√°t hi·ªán:")
                    fruit_counts = {fruit: 0 for fruit in FRUIT_CLASSES}
                    for detection in detected_fruits:
                        fruit_counts[detection["class"]] += 1
                    for fruit, count in fruit_counts.items():
                        if count > 0:
                            st.write(f"- {fruit}: {count} tr√°i")
                    total_fruits = sum(fruit_counts.values())
                    st.write(f"**T·ªïng s·ªë tr√°i c√¢y**: {total_fruits}")
                else:
                    st.warning("Kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c tr√°i c√¢y n√†o trong ·∫£nh.")

                # T√πy ch·ªçn t·∫£i xu·ªëng ·∫£nh ƒë√£ x·ª≠ l√Ω
                if st.button("üíæ T·∫£i xu·ªëng ·∫£nh ƒë√£ x·ª≠ l√Ω"):
                    _, encoded_img = cv2.imencode('.png', img)
                    st.download_button(
                        label="Nh·∫•n ƒë·ªÉ t·∫£i xu·ªëng",
                        data=encoded_img.tobytes(),
                        file_name="processed_fruit.png",
                        mime="image/png"
                    )